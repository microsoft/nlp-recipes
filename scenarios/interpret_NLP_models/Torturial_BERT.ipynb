{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explain a saved pytorch NLP model\n",
    "\n",
    "*This is a torturial on how to explain any saved pytorch model. We use pre-trained BERT model for simplicity as an example*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Phi, x, words and regularization term\n",
    "\n",
    "we first load the pre-trained model we need to explain and define the sentence we use in our case. The sentence we use is `rare bird has more than enough charm to make it memorable.`, and the layer we explain in BERT is the 3rd layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert import BertModel, BertTokenizer\n",
    "import torch\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# the sentence in our case.\n",
    "text = \"rare bird has more than enough charm to make it memorable.\"\n",
    "\n",
    "# get the tokenized words.\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "words = [\"[CLS]\"] + tokenizer.tokenize(text) + [\"[SEP]\"]\n",
    "\n",
    "# load bert model\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\").to(device)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.eval()\n",
    "\n",
    "# get the x (here we get x by hacking the code in the bert package)\n",
    "tokenized_ids = tokenizer.convert_tokens_to_ids(words)\n",
    "segment_ids = [0 for _ in range(len(words))]\n",
    "token_tensor = torch.tensor([tokenized_ids], device=device)\n",
    "segment_tensor = torch.tensor([segment_ids], device=device)\n",
    "x = model.embeddings(token_tensor, segment_tensor)[0]\n",
    "\n",
    "# here, we load the regularization we already calculated for simplicity\n",
    "regularization = json.load(open(\"regular.json\", \"r\"))\n",
    "\n",
    "# extract the Phi we need to explain\n",
    "def Phi(x):\n",
    "    global model\n",
    "    x = x.unsqueeze(0)\n",
    "    attention_mask = torch.ones(x.shape[:2]).to(x.device)\n",
    "    extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "    extended_attention_mask = extended_attention_mask.to(dtype=torch.float)\n",
    "    extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "    # extract the 3rd layer\n",
    "    model_list = model.encoder.layer[:3]\n",
    "    hidden_states = x\n",
    "    for layer_module in model_list:\n",
    "        hidden_states = layer_module(hidden_states, extended_attention_mask)\n",
    "    return hidden_states[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain the Phi and x\n",
    "\n",
    "We first initialize an interpreter class, and pass necessary parameters in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_nlp.interpreter.Interpreter import Interpreter\n",
    "\n",
    "interpreter = Interpreter(x=x, Phi=Phi, regularization=regularization, words=words).to(\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We optimize the interpreter to get the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.optimize(iteration=5000, lr=0.01, show_progress=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can get the sigma we have optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.17756101, 0.14380291, 0.15160355, 0.23105706, 0.21252151,\n",
       "       0.20955776, 0.18730533, 0.1380216 , 0.26319018, 0.23216105,\n",
       "       0.24160075, 0.13294625, 0.27567503, 0.3655964 ], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.get_sigma()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we visualize the explained result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "interpreter.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the word 'rare', 'bird', 'charm', 'memorable' is important to the third layer."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
