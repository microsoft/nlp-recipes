{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License.\n",
    "\n",
    "### Intel NLP-Architect ABSA on AzureML \n",
    "This notebook contains an end-to-end walkthrough of using Azure Machine Learning Service to train, finetune and test [Aspect Based Sentiment Analysis Models using Intel's NLP Architect](http://nlp_architect.nervanasys.com/absa.html)\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "Understand the architecture and terms introduced by Azure Machine Learning (AML)\n",
    "\n",
    "Install the Python SDK: make sure to install notebook, and contrib\n",
    "\n",
    "conda create -n azureml -y Python=3.6\n",
    "source activate azureml\n",
    "pip install --upgrade azureml-sdk[notebooks,contrib] \n",
    "conda install ipywidgets\n",
    "jupyter nbextension install --py --user azureml.widgets\n",
    "jupyter nbextension enable azureml.widgets --user --py\n",
    "\n",
    "\n",
    "You will need to restart jupyter after this Detailed instructions are [here](https://docs.microsoft.com/en-us/azure/machine-learning/service/quickstart-create-workspace-with-python/?WT.mc_id=absa-notebook-abornst)\n",
    "\n",
    "If you need a free trial account to get started you can get one [here](https://azure.microsoft.com/en-us/offers/ms-azr-0044p/?WT.mc_id=absa-notebook-abornst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize workspace\n",
    "\n",
    "To create or access an Azure ML Workspace, you will need to import the AML library and the following information:\n",
    "* A name for your workspace\n",
    "* Your subscription id\n",
    "* The resource group name\n",
    "\n",
    "Initialize a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace/?WT.mc_id=absa-notebook-abornst) object from the existing workspace you created in the Prerequisites step or create a new one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "# subscription_id = ''\n",
    "# resource_group  = ''\n",
    "# workspace_name  = ''\n",
    "# ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n",
    "# ws.write_config()\n",
    "\n",
    "try:\n",
    "    ws = Workspace.from_config()\n",
    "    print(ws.name, ws.location, ws.resource_group, ws.location, sep='\\t')\n",
    "    print('Library configuration succeeded')\n",
    "except:\n",
    "    print('Workspace not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two computer option run once(preview) and persistent compute for this demo we will use persistent compute to learn more about run once compute check out the [docs](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-set-up-training-targets#amlcompute?WT.mc_id=absa-notebook-abornst)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Choose a name for your CPU cluster\n",
    "cluster_name = \"absa-cluster\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D3_V2',\n",
    "                                                           vm_priority='lowpriority',\n",
    "                                                           min_nodes=1,\n",
    "                                                           max_nodes=1)\n",
    "    cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Data\n",
    "\n",
    "The dataset we are using comes from trip advisor and is in the open domain, this can be replaced with any csv file with rows of text as the absa model is unsupervised. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Target already exists. Skipping upload for datasets/absa/tripadvisor_co_uk-travel_restaurant_reviews_sample_2000_train.csv\n",
      "Uploaded 0 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_workspaceblobstore"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os                            \n",
    "lib_root = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "ds = ws.get_default_datastore()\n",
    "ds. upload_files([os.path.join(lib_root,'datasets/absa/tripadvisor_co_uk-travel_restaurant_reviews_sample_2000_train.csv')], \n",
    "                 relative_root=lib_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "import argparse\n",
    "import os \n",
    "from azureml.core import Run\n",
    "from spacy.cli.download import download as spacy_download\n",
    "from nlp_architect.models.absa.train.train import TrainSentiment\n",
    "from nlp_architect.models.absa import TRAIN_OUT\n",
    "from nlp_architect.utils.io import download_unzip\n",
    "\n",
    "spacy_download('en')\n",
    "EMBEDDING_URL = 'http://nlp.stanford.edu/data', 'glove.840B.300d.zip'\n",
    "EMBEDDING_PATH = TRAIN_OUT / 'word_emb_unzipped' / 'glove.840B.300d.txt'\n",
    "download_unzip(*EMBEDDING_URL, EMBEDDING_PATH)\n",
    "\n",
    "parser = argparse.ArgumentParser(description='ABSA Train')\n",
    "parser.add_argument('--data_folder', type=str, dest='data_folder', help='data folder mounting point')\n",
    "parser.add_argument('--learning_rate', type=float, default=3e-5, help='learning rate')\n",
    "parser.add_argument('--epochs', type=int, default=5)\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "rerank_model = None # Path to rerank model .h5 file\n",
    "parsed_data = None\n",
    "\n",
    "tripadvisor_train = os.path.join(args.data_folder, \n",
    "                                 'datasets/absa/tripadvisor_co_uk-travel_restaurant_reviews_sample_2000_train.csv')\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "    \n",
    "\n",
    "train = TrainSentiment(parse=not parsed_data, rerank_model=rerank_model)\n",
    "\n",
    "\n",
    "opinion_lex, aspect_lex = train.run(data=tripadvisor_train,\n",
    "                                    out_dir = './outputs',\n",
    "                                    parsed_data=parsed_data)\n",
    "\n",
    "# get hold of the current run\n",
    "run = Run.get_context()\n",
    "\n",
    "run.log('Aspect Lexicon Size:', len(aspect_lex))\n",
    "run.log('Opinion Lexicon Size:', len(opinion_lex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create An Expierment\n",
    "\n",
    "Create an [Experiment](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#experiment/?WT.mc_id=absa-notebook-abornst) to track all the runs in your workspace for this distributed PyTorch tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "experiment_name = 'absa'\n",
    "\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "script_params = {\n",
    "    '--data_folder': ds,\n",
    "}\n",
    "\n",
    "# find a way to integrate nlp architect \n",
    "nlp_est = Estimator(source_directory='.',\n",
    "                   script_params=script_params,\n",
    "                   compute_target=cluster,\n",
    "                   environment_variables = {'NLP_ARCHITECT_BE':'CPU'},\n",
    "                   entry_script='train.py',\n",
    "                   pip_packages=['git+https://github.com/NervanaSystems/nlp-architect.git@absa'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Submitting /mnt/azmnt/code/Users/nlp-architect directory for run. The size of the directory >= 25 MB, so it can take a few minutes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'absa_1566394844_c9958b8f'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = exp.submit(nlp_est)\n",
    "run.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = [r for r in exp.get_runs() if r.id == 'absa_1566394844_c9958b8f'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a1328896eaa451bb5bf449e89507088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning NLP Archictect  with AzureML HyperDrive\n",
    "Although ABSA is an unsupervised method it can be fined tuned if provided with a small sample of labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive import *\n",
    "import math\n",
    "\n",
    "param_sampling = RandomParameterSampling( {\n",
    "        'asp_thresh': range(1,5),\n",
    "         'op_thresh': 2, \n",
    "         'max_iter': range(1,5)\n",
    "    }\n",
    ")\n",
    "\n",
    "hyperdrive_run_config = HyperDriveRunConfig(estimator=nlp_est,\n",
    "                                            hyperparameter_sampling=param_sampling, \n",
    "                                            primary_metric_name='f1', # This requires a modification of script to finetune on supervised data\n",
    "                                            primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                                            max_total_runs=16,\n",
    "                                            max_concurrent_runs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, lauch the hyperparameter tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperdrive_run = experiment.submit(hyperdrive_run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor HyperDrive runs\n",
    "We can monitor the progress of the runs with the following Jupyter widget. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(hyperdrive_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find and register the best model\n",
    "Once all the runs complete, we can find the run that produced the model with the highest evaluation (METRIC TBD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "print(best_run)\n",
    "print('Best Run is:\\n  F1: {0:.5f} \\n  Learning rate: {1:.8f}'.format(\n",
    "        best_run_metrics['eval_f1'][-1],\n",
    "        best_run_metrics['lr']\n",
    "     ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Model Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_lex = run.register_model(model_name='aspect_lex', model_path='outputs/train_out/generated_aspect_lex.csv')\n",
    "opinion_lex = run.register_model(model_name='opinion_lex', model_path='outputs/train_out/generated_opinion_lex_reranked.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy as web service\n",
    "Once you've tested the model and are satisfied with the results, deploy the model as a web service hosted in [Azure Container Instances](https://azure.microsoft.com/en-us/services/container-instances/?WT.mc_id=bert-notebook-abornst).\n",
    "\n",
    "To build the correct environment for ACI, provide the following:\n",
    "\n",
    "A scoring script to show how to use the model\n",
    "An environment file to show what packages need to be installed\n",
    "A configuration file to build the ACI\n",
    "The model you trained before\n",
    "\n",
    "## Create scoring script\n",
    "Create the scoring script, called score.py, used by the web service call to show how to use the model.\n",
    "\n",
    "You must include two required functions into the scoring script:\n",
    "\n",
    "The init() function, which typically loads the model into a global object. This function is run only once when the Docker container is started.\n",
    "\n",
    "The run(input_data) function uses the model to predict a value based on the input data. Inputs and outputs to the run typically use JSON for serialization and de-serialization, but other formats are supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "from azureml.core.model import Model\n",
    "from nlp_architect.models.absa.inference.inference import SentimentInference\n",
    "from spacy.cli.download import download as spacy_download\n",
    "\n",
    "\n",
    "def init():\n",
    "    \"\"\"\n",
    "    Set up the ABSA model for Inference  \n",
    "    \"\"\"\n",
    "    global inference\n",
    "    spacy_download('en')\n",
    "    aspect_lex = Model.get_model_path('aspect_lex')\n",
    "    opinion_lex = Model.get_model_path('opinion_lex')    \n",
    "    inference = SentimentInference(aspect_lex, opinion_lex)\n",
    "\n",
    "def run(raw_data):\n",
    "    \"\"\"\n",
    "    Evaluate the model and return JSON string\n",
    "    \"\"\"\n",
    "    sentiment_doc = inference.run(doc=raw_data)\n",
    "    return sentiment_doc.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create configuration files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACI Config\n",
    "Create a ACI configuration file and specify the number of CPUs and gigabyte of RAM needed for your ACI container. While it depends on your model, the default of 1 core and 1 gigabyte of RAM is usually sufficient for many models. If you feel you need more later, you would have to recreate the image and redeploy the service.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               memory_gb=1,  \n",
    "                                               tags={\"data\": \"text\",  \"method\" : \"NLP Architcet ABSA\"}, \n",
    "                                               description='Predict ABSA with NLP Architect')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Enviorment File\n",
    "create an environment file, called myenv.yml, that specifies all of the script's package dependencies. This file is used to ensure that all of those dependencies are installed in the Docker image. This model needs nlp-architect and the azureml-sdk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "pip = [\"azureml-defaults\", \"azureml-monitoring\", \"git+https://github.com/NervanaSystems/nlp-architect.git@absa\"]\n",
    "\n",
    "myenv = CondaDependencies.create(pip_packages=pip)\n",
    "\n",
    "with open(\"myenv.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Environment Config\n",
    "Create a Enviorment configuration file and specify the enviroment and enviormental variables required for the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "deploy_env = Environment.from_conda_specification('absa_env', \"myenv.yml\")\n",
    "deploy_env.environment_variables={'NLP_ARCHITECT_BE': 'CPU'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference Config \n",
    "Create an inference configuration that recieves the deployment enviorment and the entry script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "inference_config = InferenceConfig(environment=deploy_env,\n",
    "                                   entry_script=\"score.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy in ACI\n",
    "Estimated time to complete: about 7-8 minutes\n",
    "\n",
    "Configure the image and deploy. The following code goes through these steps:\n",
    "\n",
    "Build an image using:\n",
    "The scoring file (score.py)\n",
    "The environment file (myenv.yml)\n",
    "The model file\n",
    "Register that image under the workspace.\n",
    "Send the image to the ACI container.\n",
    "Start up a container in ACI using the image.\n",
    "Get the web service HTTP endpoint.\n",
    "https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-deploy-azure-container-instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating service\n",
      "Running.........................................\n",
      "SucceededACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n",
      "CPU times: user 397 ms, sys: 69.6 ms, total: 466 ms\n",
      "Wall time: 3min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "from azureml.core.model import Model\n",
    "\n",
    "aspect_lex = Model(ws, 'aspect_lex')\n",
    "opinion_lex = Model(ws, 'opinion_lex')    \n",
    "\n",
    "service = Model.deploy(workspace=ws,\n",
    "                       name='absa-srvc', \n",
    "                       models=[aspect_lex, opinion_lex],\n",
    "                       inference_config=inference_config, \n",
    "                       deployment_config=aciconfig)\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View service logs: This is powerful for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /azureml-envs/azureml_e748c621598b8a5948a2f7276c7bb60c/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_e748c621598b8a5948a2f7276c7bb60c/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_e748c621598b8a5948a2f7276c7bb60c/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_e748c621598b8a5948a2f7276c7bb60c/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "2019-08-26T13:07:50,262247639+00:00 - gunicorn/run \n",
      "2019-08-26T13:07:50,262797544+00:00 - iot-server/run \n",
      "2019-08-26T13:07:50,262247539+00:00 - rsyslog/run \n",
      "2019-08-26T13:07:50,263256549+00:00 - nginx/run \n",
      "bash: /azureml-envs/azureml_e748c621598b8a5948a2f7276c7bb60c/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_e748c621598b8a5948a2f7276c7bb60c/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_e748c621598b8a5948a2f7276c7bb60c/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_e748c621598b8a5948a2f7276c7bb60c/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_e748c621598b8a5948a2f7276c7bb60c/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_e748c621598b8a5948a2f7276c7bb60c/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (12)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 37\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "/bin/bash: /azureml-envs/azureml_e748c621598b8a5948a2f7276c7bb60c/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "2019-08-26T13:07:55,845199922+00:00 - iot-server/finish 1 0\n",
      "2019-08-26T13:07:55,846288933+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Initializing logger\n",
      "Starting up app insights client\n",
      "Starting up request id generator\n",
      "Starting up app insight hooks\n",
      "Invoking user's init function\n",
      "Collecting en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz (11.1MB)\n",
      "Building wheels for collected packages: en-core-web-sm\n",
      "  Building wheel for en-core-web-sm (setup.py): started\n",
      "  Building wheel for en-core-web-sm (setup.py): finished with status 'done'\n",
      "  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.1.0-cp36-none-any.whl size=11074435 sha256=57529de5476488be86a3aacd1d1228af49ffcfd106e71516c94f39750dbd060a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-dylq_y2m/wheels/39/ea/3b/507f7df78be8631a7a3d7090962194cf55bc1158572c0be77f\n",
      "Successfully built en-core-web-sm\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-2.1.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/azureml-envs/azureml_e748c621598b8a5948a2f7276c7bb60c/lib/python3.6/site-packages/en_core_web_sm\n",
      "-->\n",
      "/azureml-envs/azureml_e748c621598b8a5948a2f7276c7bb60c/lib/python3.6/site-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n",
      "2019-08-26 13:08:04,646 | azureml.core.run | DEBUG | Could not load run context RunEnvironmentException:\n",
      "\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\n",
      "\tInnerException None\n",
      "\tErrorResponse {\"error\": {\"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"}}, switching offline: False\n",
      "2019-08-26 13:08:04,647 | azureml.core.run | DEBUG | Could not load the run context and allow_offline set to False\n",
      "2019-08-26 13:08:04,647 | azureml.core.model | DEBUG | RunEnvironmentException: RunEnvironmentException:\n",
      "\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\n",
      "\tInnerException RunEnvironmentException:\n",
      "\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\n",
      "\tInnerException None\n",
      "\tErrorResponse {\"error\": {\"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"}}\n",
      "\tErrorResponse {\"error\": {\"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"}}\n",
      "2019-08-26 13:08:04,647 | azureml.core.model | DEBUG | version is None. Latest version is 2\n",
      "2019-08-26 13:08:04,647 | azureml.core.model | DEBUG | Found model path at azureml-models/aspect_lex/2/generated_aspect_lex.csv\n",
      "2019-08-26 13:08:04,647 | azureml.core.run | DEBUG | Could not load run context RunEnvironmentException:\n",
      "\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\n",
      "\tInnerException None\n",
      "\tErrorResponse {\"error\": {\"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"}}, switching offline: False\n",
      "2019-08-26 13:08:04,647 | azureml.core.run | DEBUG | Could not load the run context and allow_offline set to False\n",
      "2019-08-26 13:08:04,647 | azureml.core.model | DEBUG | RunEnvironmentException: RunEnvironmentException:\n",
      "\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\n",
      "\tInnerException RunEnvironmentException:\n",
      "\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\n",
      "\tInnerException None\n",
      "\tErrorResponse {\"error\": {\"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"}}\n",
      "\tErrorResponse {\"error\": {\"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"}}\n",
      "2019-08-26 13:08:04,648 | azureml.core.model | DEBUG | version is None. Latest version is 1\n",
      "2019-08-26 13:08:04,648 | azureml.core.model | DEBUG | Found model path at azureml-models/opinion_lex/1/generated_opinion_lex_reranked.csv\n",
      "Using pre-trained BIST model.\n",
      "Downloading pre-trained BIST model...\n",
      "Downloading file to: /root/nlp-architect/cache/bist-pretrained/bist-pretrained.zip\n",
      "  0%|          | 0/24 [00:00<?, ?MB/s]\n",
      "  4%|▍         | 1/24 [00:00<00:08,  2.57MB/s]\n",
      " 12%|█▎        | 3/24 [00:00<00:06,  3.38MB/s]\n",
      " 33%|███▎      | 8/24 [00:00<00:03,  4.63MB/s]\n",
      " 58%|█████▊    | 14/24 [00:00<00:01,  6.28MB/s]\n",
      " 83%|████████▎ | 20/24 [00:01<00:00,  8.38MB/s]\n",
      "25MB [00:01, 22.74MB/s]\n",
      "[dynet] random seed: 2734000164\n",
      "[dynet] allocating memory: 512MB\n",
      "[dynet] memory allocation done.\n",
      "Download Complete\n",
      "Unzipping...\n",
      "Done.\n",
      "Users's init has completed successfully\n",
      "Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = ws.webservices['absa-srvc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the scoring web service's HTTP endpoint, which accepts REST client calls. This endpoint can be shared with anyone who wants to test the web service or integrate it into an application.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://401d4329-3c4c-4187-97ec-3cad2d439708.eastus.azurecontainer.io/score\n"
     ]
    }
   ],
   "source": [
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Deployed ACI Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"_doc_text\": \"The ambiance is charming. Uncharacteristically, the service was DREADFUL.              When we wanted to pay our bill at the end of the evening, our waitress was nowhere to be found...\", \"_sentences\": [{\"_start\": 0, \"_end\": 24, \"_events\": [[{\"_text\": \"ambiance\", \"_type\": \"ASPECT\", \"_polarity\": \"POS\", \"_score\": 1.0, \"_start\": 4, \"_len\": 8}, {\"_text\": \"charming\", \"_type\": \"OPINION\", \"_polarity\": \"POS\", \"_score\": 1.0, \"_start\": 16, \"_len\": 8}]]}, {\"_start\": 26, \"_end\": 72, \"_events\": [[{\"_text\": \"service\", \"_type\": \"ASPECT\", \"_polarity\": \"NEG\", \"_score\": -1.0, \"_start\": 52, \"_len\": 7}, {\"_text\": \"DREADFUL\", \"_type\": \"OPINION\", \"_polarity\": \"NEG\", \"_score\": -1.0, \"_start\": 64, \"_len\": 8}]]}, {\"_start\": 87, \"_end\": 183, \"_events\": [[{\"_text\": \"waitress\", \"_type\": \"ASPECT\", \"_polarity\": \"NEG\", \"_score\": -0.98065746, \"_start\": 149, \"_len\": 8}, {\"_text\": \"waitress\", \"_type\": \"OPINION\", \"_polarity\": \"NEG\", \"_score\": -0.98065746, \"_start\": 149, \"_len\": 8}]]}]}'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from nlp_architect.models.absa.inference.data_types import TermType\n",
    "\n",
    "# send a random row from the test set to score\n",
    "input_data = \"The ambiance is charming. Uncharacteristically, the service was DREADFUL.\\\n",
    "              When we wanted to pay our bill at the end of the evening, our waitress was nowhere to be found...\"\n",
    "\n",
    "headers = {'Content-Type':'application/json'}\n",
    "\n",
    "resp = requests.post(service.scoring_uri, input_data, headers=headers)\n",
    "resp.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render the response using [Displacy](https://spacy.io/usage/visualizers/)\n",
    "Note ```Spacy``` Must be installed on the local machine for this to work can be installed with ```pip install spacy```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The \n",
       "<mark class=\"entity\" style=\"background: #7CFC00; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    ambiance\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">POS</span>\n",
       "</mark>\n",
       " is charming. Uncharacteristically, the \n",
       "<mark class=\"entity\" style=\"background: #FF0000; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    service\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NEG</span>\n",
       "</mark>\n",
       " was DREADFUL.              When we wanted to pay our bill at the end of the evening, our \n",
       "<mark class=\"entity\" style=\"background: #FF0000; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    waitress\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NEG</span>\n",
       "</mark>\n",
       " was nowhere to be found...</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "if resp.text:\n",
    "    doc = json.loads(resp.json()) # load response as dictionary\n",
    "    doc_viz = {'text':doc[\"_doc_text\"], 'ents':[]}\n",
    "    for s in doc[\"_sentences\"]:\n",
    "        for e in s[\"_events\"][0]:\n",
    "            if e[\"_type\"] == \"ASPECT\":\n",
    "                doc_viz['ents'].append({'start': e[\"_start\"], 'end': e[\"_start\"] + e[\"_len\"], 'label':str(e[\"_polarity\"])})\n",
    "    doc_viz['ents'].sort(key=lambda m: m[\"start\"])\n",
    "    displacy.render(doc_viz, style=\"ent\", options={'colors':{'POS':'#7CFC00', 'NEG':'#FF0000'}}, manual=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
